{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p><code>brec</code> is a tool that allows you to quickly and easily create a custom message exchange protocol with resilience to data \"corruption\" and the ability to extract messages from mixed streams (i.e., streams containing not only <code>brec</code> packets but also any other data). <code>brec</code> is developed for designing your own custom binary protocol \u2014 without predefined message formats or rigid schemas.</p> <p>Notice: Public Beta</p> <p>The <code>brec</code> is currently in a public beta phase. Its core functionality has demonstrated strong reliability under heavy stress testing, and the system is considered stable for most use cases.</p> <p>However, the public API is still evolving as we work to support a wider range of scenarios. We welcome your feedback and would be grateful if you share which features or improvements would make brec more valuable for your needs.</p> <p>Thanks for being part of the journey!</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Protocol without constraints \u2013 Unlike many alternatives, <code>brec</code> doesn\u2019t enforce a fixed message layout. Instead, you define your own building blocks (<code>blocks</code>) and arbitrary payloads (<code>payloads</code>), combining them freely into custom packets.</li> <li>Stream-recognizable messages \u2013 Each block, payload, and packet is automatically assigned a unique signature, making them easily discoverable within any byte stream.</li> <li>Built-in reliability \u2013 All parts of a packet (blocks, payloads, and headers) are automatically linked with their own CRC checksums to ensure data integrity.</li> <li>Stream-aware reading \u2013 <code>brec</code> includes a powerful streaming reader capable of extracting packets even from noisy or corrupted streams \u2014 skipping irrelevant or damaged data without breaking.</li> <li>Non-packet data is preserved \u2013 When reading mixed streams, unrecognized data is not lost. You can capture and process it separately using rules and callbacks.</li> <li>Persistent storage layer \u2013 <code>brec</code> provides a high-performance storage engine for persisting packets. Its slot-based layout enables fast indexed access, filtering, and direct access by packet index.</li> <li>High performance \u2013 Parsing performance is on par with the most optimized binary parsers (see the Performance section in performance).</li> <li>Simple to use \u2013 Just annotate your structs with #[block] or #[payload], and brec takes care of the rest \u2014 your protocol is ready to go.</li> </ul>"},{"location":"#recent-performance-test-results","title":"Recent Performance Test Results","text":"Test Mode Size Rows Time (ms) Iterations Storage (brec) Filtering 908 Mb 140,000 612 10 Storage (brec) Reading 908 Mb 1,000,000 987 10 JSON Reading 919 Mb 1,000,000 597 10 JSON Filtering 919 Mb 140,000 608 10 Binary Stream (brec) Reading 831 Mb 1,000,000 764 10 Binary Stream (brec) Filtering 831 Mb 140,000 340 10 Plain Text Reading 774 Mb 1,000,000 247 10 Plain Text Filtering 774 Mb 150,000 276 10 Streamed Storage (brec) Filtering 908 Mb 140,000 355 10 Streamed Storage (brec) Reading 908 Mb 1,000,000 790 10 <p>See more details in the test about how tests are performed and what they mean.</p>"},{"location":"LICENSE/","title":"LICENSE","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright [yyyy] [name of copyright owner]</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"code_generation/","title":"Code Generation","text":"<p><code>brec</code> generates code in two stages:</p> <ul> <li> <p>When the <code>#[block]</code> macro is used, it generates code specific to the corresponding block.   The same applies to the <code>#[payload]</code> macro, which generates code related to a specific payload type.</p> </li> <li> <p>However, the protocol also requires unified types such as <code>enum Block</code> (enumerating all user-defined blocks)   and <code>enum Payload</code> (enumerating all payloads). These general-purpose enums allow the system to handle   various blocks and payloads dynamically.</p> </li> </ul> <p>To generate this unified code, the <code>generate!()</code> macro must be invoked:</p> <pre><code>pub use blocks::*;\npub use payloads::*;\n\nbrec::generate!();\n</code></pre> <p>This macro must be called exactly once per crate and is responsible for:</p> <ul> <li>Implementing required <code>brec</code> traits for all user-defined <code>Block</code> types</li> <li>Implementing required <code>brec</code> traits for all user-defined <code>Payload</code> types</li> <li>Generating unified enums for blocks: <code>enum Block { ... }</code></li> <li>Generating unified enums for payloads: <code>enum Payload { ... }</code></li> <li>Exporting several convenience type aliases to simplify usage</li> </ul>"},{"location":"code_generation/#generated-aliases","title":"Generated Aliases","text":"<p>The macro defines the following aliases to reduce verbosity when using <code>brec</code> types:</p> Alias Expanded to <code>Packet</code> <code>PacketDef&lt;Block, Payload, Payload&gt;</code> <code>PacketBufReader&lt;'a, R&gt;</code> <code>PacketBufReaderDef&lt;'a, R, Block, BlockReferred&lt;'a&gt;, Payload, Payload&gt;</code> <code>Rules&lt;'a&gt;</code> <code>RulesDef&lt;Block, BlockReferred&lt;'a&gt;, Payload, Payload&gt;</code> <code>Rule&lt;'a&gt;</code> <code>RuleDef&lt;Block, BlockReferred&lt;'a&gt;, Payload, Payload&gt;</code> <code>RuleFnDef&lt;D, S&gt;</code> <code>RuleFnDef&lt;D, S&gt;</code> <code>Storage&lt;S&gt;</code> <code>StorageDef&lt;S, Block, BlockReferred&lt;'static&gt;, Payload, Payload&gt;</code> <p>These aliases make it easier to work with generated structures and remove the need to repeat generic parameters.</p>"},{"location":"code_generation/#required-build-script","title":"Required Build Script","text":"<p>To enable this macro, you must include a <code>build.rs</code> file with the following content:</p> <pre><code>    brec::build_setup();\n</code></pre> <p>This step ensures the code generator runs during build and provides all required metadata.</p>"},{"location":"code_generation/#usage-constraints","title":"Usage Constraints","text":"<ul> <li>The macro must only be called once per crate. Calling it more than once will result in compilation errors due to duplicate types and impls.</li> <li>The macro must see all relevant types (<code>Block</code>, <code>Payload</code>) in scope. You must ensure they are visible in the location where you call the macro.</li> </ul>"},{"location":"code_generation/#visibility-requirements","title":"Visibility Requirements","text":"<p>Ensure that all blocks and payloads are imported at the location where the macro is used:</p> <pre><code>pub use blocks::*;\npub use payloads::*;\n\nbrec::generate!();\n</code></pre>"},{"location":"code_generation/#parameters","title":"Parameters","text":"<p>The macro can be used with the following parameters:</p> <ul> <li> <p><code>no_default_payload</code> \u2013 Disables the built-in payloads (<code>String</code> and <code>Vec&lt;u8&gt;</code>).   This has no impact on runtime performance but may slightly improve compile times and reduce binary size.</p> </li> <li> <p><code>payloads_derive = \"Trait\"</code> \u2013   By default, <code>brec</code> automatically collects all <code>derive</code> attributes that are common across user-defined payloads   and applies them to the generated <code>Payload</code> enum.   This parameter allows you to manually specify additional derives for the <code>Payload</code> enum\u2014useful if you are   only using the built-in payloads (<code>String</code>, <code>Vec&lt;u8&gt;</code>) and do not define custom ones.</p> </li> </ul> <p>For example,</p> <pre><code>pub use blocks::*;\n\n// You don't define any custom payloads and only want to use the built-in ones (`String`, `Vec&lt;u8&gt;`)\nbrec::generate!(payloads_derive = \"Debug, Clone\");\n</code></pre> <pre><code>pub use blocks::*;\n\n// You don't define any payloads and explicitly disable the built-in ones\nbrec::generate!(no_default_payload);\n</code></pre> <p>If the user fully disables payload support (as in the example above), the macro will not generate any packet-related types (see Generated Aliases).</p>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#your-protocol-in-5-steps","title":"Your Protocol in 5 Steps","text":""},{"location":"getting_started/#create-a-crate","title":"Create a Crate","text":"<p>It\u2019s best to create a separate crate for your protocol. This helps keep your code clean and organized. Simply create a new crate and include it in your project\u2019s workspace.</p>"},{"location":"getting_started/#define-blocks","title":"Define Blocks","text":"<p>Decide on the blocks for your protocol. Just create Rust structs and annotate them with the <code>#[block]</code> macro.</p> <pre><code>#[block]\npub struct MyBlock {\n    pub field_u8: u8,\n    pub field_u32: u32,\n    pub field_u64: u64,\n    pub blob: [u8; 1000],\n}\n</code></pre>"},{"location":"getting_started/#define-payload","title":"Define Payload","text":"<p>Once the blocks are ready, define the payload. Annotate a struct or enum with the <code>#[payload(bincode)]</code> macro. (We recommend starting with the bincode feature.)</p> <pre><code>#[derive(Default, serde::Deserialize, serde::Serialize)]\npub enum MyNestedEntity {\n    One(String),\n    Two(Vec&lt;u8&gt;),\n    #[default]\n    Three,\n}\n\n#[payload(bincode)]\n#[derive(Default, serde::Deserialize, serde::Serialize)]\npub struct MyPayload {\n    pub field_u8: u8,\n    pub field_u16: u16,\n    pub field_u32: u32,\n    pub field_u64: u64,\n    pub field_u128: u128,\n    pub field_nested: MyNestedEntity,\n}\n</code></pre>"},{"location":"getting_started/#add-code-generation","title":"Add Code Generation","text":"<p>You must call brec::generate!() in a single location in your code to let brec generate the required code for your blocks and payloads. The best place to do this is in the lib.rs file of the crate you created. Make sure all blocks and payloads are in scope at the call site of <code>brec::generate!()</code>.</p> <pre><code>use blocks::*; // Make your blocks visible\nuse payloads::*; // Make your payloads visible\n\n// Let `brec` generate a code\nbrec::generate!();\n</code></pre>"},{"location":"getting_started/#final-step","title":"Final Step","text":"<p>Add a simple <code>build.rs</code> script.</p> <pre><code>    brec::build_setup();\n</code></pre>"},{"location":"getting_started/#done","title":"Done","text":"<p>Your protocol is ready to be used and you can create your first packet</p> <pre><code>let my_packet = Packet::new(\n    // You are limited to 255 blocks per packet.\n    vec![\n        Block::MyBlock(MyBlock::default()),\n    ],\n    // Note: payload is optional\n    Some(Payload::MyPayload(MyPayload::default()))\n);\n</code></pre>"},{"location":"getting_started/#blocks-and-payloads-in-details","title":"Blocks and Payloads in details","text":"<p><code>brec</code> includes powerful macros that allow defining the components of a protocol with minimal effort. For example, to define a structure as a block (<code>Block</code>), you simply need to use the <code>block</code> macro:</p> <pre><code>#[brec::block]\npub struct MyBlock {\n    pub field_u8: u8,\n    pub field_u16: u16,\n    pub field_u32: u32,\n    pub field_u64: u64,\n    pub field_u128: u128,\n    pub field_i8: i8,\n    pub field_i16: i16,\n    pub field_i32: i32,\n    pub field_i64: i64,\n    pub field_i128: i128,\n    pub field_f32: f32,\n    pub field_f64: f64,\n    pub field_bool: bool,\n    pub blob_a: [u8; 1],\n    pub blob_b: [u8; 100],\n    pub blob_c: [u8; 1000],\n    pub blob_d: [u8; 10000],\n}\n</code></pre> <p>The <code>block</code> macro automatically generates all the necessary code for <code>MyBlock</code> to function as a block. Specifically, it adds: - A unique block signature based on its name and path. - A <code>CRC</code> field to ensure data integrity.</p> <p>All user-defined blocks are ultimately included in a generated enumeration <code>Block</code>, as shown in the example:</p> <pre><code>#[brec::block]\npub struct MyBlockA {\n    pub field: u8,\n    pub blob: [u8; 100],\n}\n\n#[brec::block]\npub struct MyBlockB {\n    pub field_u16: u16,\n    pub field_u32: u32,\n}\n\n#[brec::block]\npub struct MyBlockC {\n    pub field: u64,\n    pub blob: [u8; 10000],\n}\n\n// Instruct `brec` to generate and include all protocol types\nbrec::generate!();\n\n// Generated by `brec`\npub enum Block {\n    MyBlockA(MyBlockA),\n    MyBlockB(MyBlockB),\n    MyBlockC(MyBlockC),\n}\n</code></pre> <p>The generated <code>Block</code> enumeration is always returned to the user as a result of message (packet) parsing, allowing for easy identification of blocks by their names.</p> <p>Similarly to blocks, defining a payload can be done with a simple call to the <code>payload</code> macro.</p> <pre><code>#[derive(serde::Deserialize, serde::Serialize)]\npub enum MyNestedEntity {\n    One(String),\n    Two(Vec&lt;u8&gt;),\n    Three,\n}\n\n#[payload(bincode)]\n#[derive(serde::Deserialize, serde::Serialize)]\npub struct MyPayload {\n    pub field_u8: u8,\n    pub field_u16: u16,\n    pub field_u32: u32,\n    pub field_u64: u64,\n    pub field_u128: u128,\n    pub field_nested: MyNestedEntity,\n}\n</code></pre> <p>A payload is an unrestricted set of data (unlike <code>Block</code>, which is limited to primitive data). It can be either a <code>struct</code> or an <code>enum</code> with unlimited nesting levels. Additionally, there are no restrictions on the use of generic types.</p> <p><code>brec</code> imposes only one requirement for payloads: they must implement the traits <code>PayloadEncode</code> and <code>PayloadDecode&lt;T&gt;</code>, which enable encoding and decoding of data into target types.</p> <p>Out of the box (with the <code>bincode</code> feature), <code>brec</code> provides automatic support for the required traits by leveraging the <code>bincode</code> crate. This means that to define a fully functional payload, it is enough to use <code>#[payload(bincode)]</code>, eliminating the need for manually implementing the <code>PayloadEncode</code> and <code>PayloadDecode&lt;T&gt;</code> traits. </p> <p>Note that <code>bincode</code> requires serialization and deserialization support, which is why the previous examples include <code>#[derive(serde::Deserialize, serde::Serialize)]</code>.</p> <p>With <code>brec</code>, defining protocol types (blocks and payloads) is reduced to simply defining structures and annotating them with the <code>block</code> and <code>payload</code> macros.</p>"},{"location":"getting_started/#simple-packet-construction","title":"Simple Packet Construction","text":"<p>Once the protocol data types have been defined, the next step is to include the \"unifying\" code generated by <code>brec</code> using <code>brec::generate!();</code></p> <pre><code>#[brec::block]\npub struct MyBlockA { ... }\n\n#[brec::block]\npub struct MyBlockB { ... }\n\n#[brec::block]\npub struct MyBlockC { ... }\n\n#[payload(bincode)]\n#[derive(serde::Deserialize, serde::Serialize)]\npub struct MyPayloadA { ... }\n\n#[payload(bincode)]\n#[derive(serde::Deserialize, serde::Serialize)]\npub struct MyPayloadB { ... }\n\n#[payload(bincode)]\n#[derive(serde::Deserialize, serde::Serialize)]\npub struct MyPayloadC { ... }\n\n// Instruct `brec` to generate and include all protocol types\nbrec::generate!();\n\n// Now available:\n\n// Generalized block representation\npub enum Block {\n    MyBlockA(MyBlockA),\n    MyBlockB(MyBlockB),\n    MyBlockC(MyBlockC),\n}\n\n// Generalized payload representation\npub enum Payload {\n    MyPayloadA(MyPayloadA),\n    MyPayloadB(MyPayloadB),\n    MyPayloadC(MyPayloadC),\n}\n\n// Packet type\npub type Packet = brec::PacketDef&lt;Block, Payload, Payload&gt;;\n</code></pre> <p>Once all protocol types are defined and the unifying code is generated, you can start creating packets:</p> <pre><code>let my_packet = Packet::new(\n    // You are limited to 255 blocks per packet.\n    vec![\n        Block::MyBlockA(MyBlockA::default()),\n        Block::MyBlockC(MyBlockC::default()),\n    ],\n    // Note: payload is optional\n    Some(Payload::MyPayloadA(MyPayloadA::default()))\n);\n</code></pre> <p>At this point, your protocol is ready for use. <code>Packet</code> implements all the necessary methods for reading from and writing to a data source.</p>"},{"location":"getting_started/#code-generation-note","title":"Code Generation Note","text":"<p>Pay special attention: using <code>brec</code> involves code generation. Therefore, after defining the structure of your protocol (<code>blocks</code> and <code>payloads</code>), you must call <code>brec::generate!()</code>. This macro can be invoked only once and only in a single location in your code.</p> <p>Additionally, you will need to add a very simple <code>build.rs</code> script. For more details, see the Code Generation section.</p>"},{"location":"getting_started/#performance-security-and-efficiency","title":"Performance, Security, and Efficiency","text":"<p><code>brec</code> is a binary protocol, meaning data is always transmitted and stored in a binary format.</p> <p>The protocol ensures security through the following mechanisms: - Each block includes a unique signature generated based on the block's name. Name conflicts within a single crate are eliminated, as the module path is taken into account. - Similar to blocks, each payload also has a unique signature derived from its name. - Additionally, <code>Packet</code> itself has a fixed 64-bit signature.</p> <p>These features enable reliable entity recognition within a data stream. Furthermore, blocks, payloads, and the packet itself have their own CRCs. While blocks always use a 32-bit CRC, payloads allow for optional support of 64-bit or 128-bit CRC to enhance protocol security.</p> <p><code>brec</code> ensures maximum performance through the following optimizations: - Minimization of data copying and cloning operations. - Incremental packet parsing: first, blocks are parsed, allowing the user to inspect them and decide whether the packet should be fully parsed (including the payload) or skipped. This enables efficient packet filtering based on block values, avoiding the overhead of parsing a heavy payload. - If data integrity verification is not required, <code>brec</code> allows CRC to be disabled for all types or selectively. This improves performance by eliminating the need for hash calculations.</p> <p>The conceptual separation of a packet into blocks and a payload allows users to efficiently manage traffic load. Blocks can carry \"fast\" information that requires quick access, while the payload can implement more complex encoding/decoding mechanisms (such as data compression). Filtering based on blocks helps avoid unnecessary operations on the payload when they are not required.</p>"},{"location":"overview/","title":"Overview","text":"<p>The primary unit of information in <code>brec</code> is a packet (<code>Packet</code>) \u2014 a ready-to-transmit message with a unique signature (allowing it to be recognized within mixed data) and a CRC to ensure data integrity.</p> <p>A packet consists of a set of blocks (<code>Block</code>) and, optionally, a payload (<code>Payload</code>).</p> <p></p> <p>Blocks (<code>Block</code>) are the minimal units of information in the <code>brec</code> system. A block can contain only primitives, such as numbers, boolean values, and byte slices. A block serves as a kind of packet index, allowing for quick determination of whether a packet requires full processing (i.e., parsing the <code>Payload</code>) or can be ignored.</p> <p>The payload (<code>Payload</code>) is an optional part of the packet. Unlike blocks (<code>Block</code>), it has no restrictions on the type of data it can contain\u2014it can be a <code>struct</code> or <code>enum</code> of any complexity and nesting level.</p> <p>Unlike most protocols, <code>brec</code> does not require users to define a fixed set of messages but does require them to describe blocks (<code>Block</code>) and payload data (<code>Payload</code>).</p> <p>Users can construct packets (messages) by combining various sets of blocks and payloads. This means <code>brec</code> does not impose a predefined list of packets (<code>Packet</code>) within the protocol but allows them to be defined dynamically. As a result, the same block and/or payload can be used across multiple packets (messages) without any restrictions.</p>"},{"location":"specification/","title":"Specification","text":""},{"location":"specification/#block","title":"Block","text":"<p>A block supports fields of the following types:</p> Type Size in Binary Format (bytes) u8 1 u16 2 u32 4 u64 8 u128 16 i8 1 i16 2 i32 4 i64 8 i128 16 f32 4 f64 8 bool 1 [u8; n] n <p>Any structure marked with the <code>block</code> macro will have the following extended representation in binary format:</p> Field Type Signature [u8; 4] User-defined fields Available types CRC [u8; 4] <p>Thus, the total binary length of a block is calculated as:</p> <pre><code>length = 4 (Signature) + Block's Fields Length + 4 (CRC)\n</code></pre> <p>The block signature is generated automatically based on its name (including the module path) and the names of all its fields. The signature hash is computed using a 32-bit algorithm.</p> <p>The block's CRC (32-bit) is generated based on the values of user-defined fields, excluding the signature and the CRC itself.</p>"},{"location":"specification/#payload","title":"Payload","text":"<p>Any data type that implements the <code>PayloadEncode</code> and <code>PayloadDecode&lt;T&gt;</code> traits can be used as a payload. These traits handle the conversion of a payload to bytes and its unpacking from bytes, respectively. When serializing a payload into binary format, <code>brec</code> automatically adds a <code>PayloadHeader</code> to each payload.</p>"},{"location":"specification/#payloadheader-structure","title":"<code>PayloadHeader</code> Structure","text":"Field Size Description Signature Length 1 byte Length of the signature: 4, 8, 16, 32, 64, or 128 bytes Signature 4 to 128 bytes Unique signature of the payload CRC Length 1 byte Length of the CRC: 4, 8, 16, 32, 64, or 128 bytes CRC 4 to 128 bytes CRC checksum of the payload Payload Body Length 4 bytes Length of the payload body (<code>u32</code>) <p>As seen in the <code>PayloadHeader</code> structure, it does not have a fixed size since the lengths of the signature and CRC can vary. For example, when using the <code>bincode</code> feature, both the signature and CRC lengths are set to 4 bytes (32 bits). However, users can implement their own versions with different lengths.</p> <p>Thus, any payload in binary format is represented as follows:</p> Component Size Description <code>PayloadHeader</code> 14 - 262 bytes Header containing metadata about the payload Payload's body --- Payload data encoded using <code>PayloadEncode</code> <p>The CRC of the payload is generated based on the bytes produced by <code>PayloadEncode</code>. This introduces some constraints on CRC verification since <code>brec</code> does not restrict the types of data used in a payload. If a payload contains data types that do not guarantee a strict byte sequence, CRC verification will always fail due to byte order variations. As a result, extracting the payload from the data stream will become impossible.</p> <p>A simple example of such a situation is a <code>HashMap</code>, which does not guarantee a consistent field order when reconstructed. For instance, defining a payload like this:</p> <pre><code>#[payload(bincode)]\n#[derive(serde::Deserialize, serde::Serialize)]\npub struct MyPayloadB {\n    items: HashMap&lt;String, String&gt;,\n}\n</code></pre> <p>would make it impossible to extract this payload, as the CRC would always be different (except when the number of keys in the map is \u2264 1). This issue can be resolved in several ways:</p> <ul> <li>The simplest approach is to avoid using \"unstable\" data types and instead choose one that guarantees a fixed byte sequence.</li> <li>Disable CRC verification for this specific payload by using the <code>no_crc</code> directive: <code>#[payload(bincode, no_crc)]</code>.</li> <li>Disable automatic CRC calculation and implement the <code>PayloadCrc</code> trait manually for the specific payload. Automatic CRC calculation can be disabled using the <code>no_auto_crc</code> directive: <code>#[payload(bincode, no_auto_crc)]</code>.</li> </ul>"},{"location":"specification/#packet","title":"Packet","text":"<p>A packet serves as a container for storing a set of blocks and optionally a single payload. Each packet includes its own header, <code>PacketHeader</code>:</p>"},{"location":"specification/#packetheader-structure","title":"<code>PacketHeader</code> Structure","text":"Field Size Description Signature 8 bytes Static packet signature Size 8 bytes Total size of the packet (excluding the <code>PacketHeader</code>) Block's length 8 bytes Total length of all blocks (including signatures and CRC) in the packet Payload existence flag 1 byte <code>0</code> - packet without payload; <code>1</code> - packet contains a payload CRC 4 bytes CRC of the <code>PacketHeader</code> (not the entire packet, only the header) <p>Thus, in binary format, a packet is structured as follows:</p> Component Size Count <code>PacketHeader</code> 29 bytes 1 <code>Block</code> --- 0 to 255 <code>Payload</code> --- 0 or 1"},{"location":"parts/blocks/","title":"Blocks","text":"<p>Any structure can be used as a block, provided it contains fields of the following types:</p> Type u8 u16 u32 u64 u128 i8 i16 i32 i64 i128 f32 f64 bool [u8; n] <p>A block can also include an <code>enum</code>, but only if it can be converted into one of the supported types. For example:</p> <pre><code>pub enum Level {\n    Err,\n    Warn,\n    Info,\n    Debug,\n}\n\n// Ensure conversion of `Level` to `u8`\nimpl From&lt;&amp;Level&gt; for u8 {\n    fn from(value: &amp;Level) -&gt; Self {\n        match value {\n            Level::Err =&gt; 0,\n            Level::Warn =&gt; 1,\n            Level::Debug =&gt; 2,\n            Level::Info =&gt; 3,\n        }\n    }\n}\n\n// Ensure conversion of `u8` to `Level`\nimpl TryFrom&lt;u8&gt; for Level {\n    type Error = String;\n    fn try_from(value: u8) -&gt; Result&lt;Self, Self::Error&gt; {\n        match value {\n            0 =&gt; Ok(Level::Err),\n            1 =&gt; Ok(Level::Warn),\n            2 =&gt; Ok(Level::Debug),\n            3 =&gt; Ok(Level::Info),\n            invalid =&gt; Err(format!(\"{invalid} isn't a valid value for Level\")),\n        }\n    }\n}\n\n#[block]\npub struct BlockWithEnum {\n    pub level: Level,\n    pub data: [u8; 200],\n}\n</code></pre> <p>A structure is declared as a block using the <code>block</code> macro. If the block is located outside the visibility scope of the <code>brec::generate!()</code> code generator call, the module path must be specified using the <code>path</code> directive:</p> <pre><code>#[block(path = mod_a::mod_b)]\npub struct BlockWithEnum {\n    pub level: Level,\n    pub data: [u8; 200],\n}\n\n// Since the `path` directive is the default, the path can also be defined directly:\n\n#[block(mod_a::mod_b)]\npub struct BlockWithEnum {\n    pub level: Level,\n    pub data: [u8; 200],\n}\n</code></pre> <p>However, in most cases, this approach is not recommended. It is better to ensure the visibility of all blocks at the location where the <code>brec::generate!()</code> code generator is invoked.</p> <p>The code generator provides support for the following traits:</p> Trait Available Methods Return Type Purpose <code>ReadBlockFrom</code> <code>read&lt;T: std::io::Read&gt;(buf: &amp;mut T, skip_sig: bool)</code> <code>Result&lt;Self, Error&gt;</code> Attempts to read a block with an option to skip signature recognition (e.g., if the signature has already been read and the user knows exactly which block is being parsed). Returns an error if reading fails for any reason. <code>ReadBlockFromSlice</code> <code>read_from_slice&lt;'b&gt;(src: &amp;'b [u8], skip_sig: bool)</code> <code>Result&lt;Self, Error&gt;</code> Attempts to read a block from a byte slice, with an option to skip signature verification. Unlike other methods, this returns a reference to a block representation generated by <code>brec</code>, rather than the user-defined block itself (see details below). <code>TryReadFrom</code> <code>try_read&lt;T: std::io::Read + std::io::Seek&gt;(buf: &amp;mut T)</code> <code>Result&lt;ReadStatus&lt;Self&gt;, Error&gt;</code> Attempts to read a block, but instead of returning an error when data is insufficient, it returns a corresponding read status. Also, it moves the source's position only upon successful reading, otherwise keeping it unchanged. <code>TryReadFromBuffered</code> <code>try_read&lt;T: std::io::BufRead&gt;(reader: &amp;mut T)</code> <code>Result&lt;ReadStatus&lt;Self&gt;, Error&gt;</code> Identical to <code>TryReadFrom</code>, except it returns a reference to the generated block representation (see details below). <code>WriteTo</code> <code>write&lt;T: std::io::Write&gt;(&amp;self, writer: &amp;mut T)</code> <code>std::io::Result&lt;usize&gt;</code> Equivalent to the standard <code>write</code> method, returning the number of bytes written to the output. Does not guarantee flushing to the output, so calling <code>flush</code> is required if such guarantees are needed. <code>WriteTo</code> <code>write_all&lt;T: std::io::Write&gt;(&amp;self, writer: &amp;mut T)</code> <code>std::io::Result&lt;()&gt;</code> Equivalent to the standard <code>write_all</code> method. <code>WriteVectoredTo</code> <code>slices(&amp;self)</code> <code>std::io::Result&lt;brec::IoSlices&gt;</code> Returns the binary representation of the block as slices. <code>WriteVectoredTo</code> <code>write_vectored&lt;T: std::io::Write&gt;(&amp;self, buf: &amp;mut T)</code> <code>std::io::Result&lt;usize&gt;</code> Attempts a vectored write of the block (analogous to the standard <code>write_vectored</code>). <code>WriteVectoredTo</code> <code>write_vectored_all&lt;T: std::io::Write&gt;(&amp;self, buf: &amp;mut T)</code> <code>std::io::Result&lt;()&gt;</code> Attempts a vectored write of the block (analogous to the standard <code>write_vectored_all</code>). <code>CrcU32</code> <code>fn crc(&amp;self)</code> <code>[u8; 4]</code> Computes the CRC of the block. <code>StaticSize</code> <code>fn ssize()</code> <code>u64</code> Returns the size of the block in bytes. <p>It is evident that all the listed write methods transmit the binary representation of the block to the output.</p> <p>As mentioned earlier, <code>brec</code> also generates a reference representation of a block:</p> <pre><code>#[block]\npub struct BlockWithEnum {\n    pub level: Level,\n    pub data: [u8; 200],\n}\n\n// Generated by `brec`\nstruct BlockWithEnumReferred&lt;'a&gt; {\n    pub level: Level,\n    pub data: &amp;'a [u8; 200],\n}\n</code></pre> <p>As seen above, the reference representation of a block does not store the slice itself but rather a reference to it. This allows the user to inspect the block while avoiding unnecessary data copying. If needed, the referenced block can be easily converted into the actual block using <code>.into()</code>, at which point the data will be copied from the source.</p>"},{"location":"parts/blocks/#block-parameters","title":"Block Parameters","text":"<p>The <code>block</code> macro can be used with the following directives:</p> <ul> <li><code>path = mod::mod</code> \u2013 Specifies the module path for the block if it is not directly imported at the location of <code>brec::generate!()</code>. This approach is not recommended (it is better to ensure block visibility at the generator call site), but it is not inherently inefficient or unstable. However, using this method may make future code maintenance more difficult.</li> <li><code>no_crc</code> \u2013 Disables CRC verification for the block. Note that this does not remove the CRC field from the binary representation of the block. The CRC field will still be present but filled with zeros, and no CRC calculation will be performed.</li> </ul>"},{"location":"parts/packets/","title":"Packets","text":"<p>Users do not need to define possible packet types since any combination of blocks (up to 255) and a single optional payload constitutes a valid packet.</p> <pre><code>brec::generate!();\n\nlet my_packet = Packet::new(\n    // You are limited to 255 blocks per packet.\n    vec![\n        Block::MyBlockA(MyBlockA::default()),\n        Block::MyBlockC(MyBlockC::default())\n    ],\n    // Note: payload is optional\n    Some(Payload::MyPayloadA(MyPayloadA::default()))\n);\n</code></pre>"},{"location":"parts/packets/#packet-constraints","title":"Packet Constraints","text":"<ul> <li>A packet can contain 0 to 255 blocks.</li> <li>A packet can include 0 or 1 payload.</li> </ul> <p>Warning! In most cases, having 1-5 blocks per packet is more than sufficient. A significant number of blocks can lead to an increase in compilation time but will not affect the performance of the compiled code. Therefore, if compilation time is a critical factor, it is recommended to avoid a large number of blocks in packets. </p> <p>To clarify, runtime performance is not affected, but the compilation time increases because the compiler has to generate multiple implementations for generic types used in <code>PacketDef</code> (an internal <code>brec</code> structure).</p>"},{"location":"parts/packets/#packet-trait-implementations","title":"Packet Trait Implementations","text":"<p>A <code>Packet</code> can be used as a standalone unit for data exchange. It implements the following traits:</p> Trait Method Return Type Description <code>ReadFrom</code> <code>read&lt;T: std::io::Read&gt;(buf: &amp;mut T)</code> <code>Result&lt;Self, Error&gt;</code> Attempts to read a packet from a source. <code>TryReadFrom</code> <code>try_read&lt;T: std::io::Read + std::io::Seek&gt;(buf: &amp;mut T)</code> <code>Result&lt;ReadStatus&lt;Self&gt;, Error&gt;</code> Attempts to read a packet, but if data is insufficient, it returns a corresponding read status instead of an error. Also, moves the source\u2019s position only upon successful reading; otherwise, it remains unchanged. <code>TryReadFromBuffered</code> <code>try_read&lt;T: std::io::BufRead&gt;(reader: &amp;mut T)</code> <code>Result&lt;ReadStatus&lt;Self&gt;, Error&gt;</code> Identical to <code>TryReadFrom</code>. <code>WriteMutTo</code> <code>write&lt;T: std::io::Write&gt;(&amp;mut self, buf: &amp;mut T)</code> <code>std::io::Result&lt;usize&gt;</code> Equivalent to the standard <code>write</code> method, returning the number of bytes written. Does not guarantee that data is flushed to the output, so calling <code>flush</code> is required if such guarantees are needed. <code>WriteMutTo</code> <code>write_all&lt;T: std::io::Write&gt;(&amp;mut self, buf: &amp;mut T)</code> <code>std::io::Result&lt;()&gt;</code> Equivalent to the standard <code>write_all</code> method. <code>WriteVectoredMutTo</code> <code>slices(&amp;mut self)</code> <code>std::io::Result&lt;IoSlices&gt;</code> Returns the binary representation of the packet as slices. <code>WriteVectoredMutTo</code> <code>write_vectored&lt;T: std::io::Write&gt;(&amp;mut self, buf: &amp;mut T)</code> <code>std::io::Result&lt;usize&gt;</code> Attempts a vectored write of the packet (analogous to the standard <code>write_vectored</code>). <code>WriteVectoredMutTo</code> <code>write_vectored_all&lt;T: std::io::Write&gt;(&amp;mut self, buf: &amp;mut T)</code> <code>std::io::Result&lt;()&gt;</code> Attempts a vectored write of the packet (analogous to the standard <code>write_vectored_all</code>)."},{"location":"parts/packets/#packet-filtering","title":"Packet Filtering","text":"<p><code>Packet</code> provides a highly useful method: </p> <pre><code>filtered&lt;R: std::io::Read + std::io::Seek&gt;(\n    reader: &amp;mut R, \n    rules: &amp;Rules\n) -&gt; Result&lt;LookInStatus&lt;Packet&gt;, Error&gt;\n</code></pre> <p>This method allows you to \"peek\" into a packet before processing the payload, which can significantly improve performance when filtering specific packets.</p>"},{"location":"parts/payloads/","title":"Payloads","text":"<p><code>brec</code> does not impose any restrictions on the type of data that can be defined as a payload. However, a payload must implement the following traits:</p>"},{"location":"parts/payloads/#required-traits","title":"Required Traits","text":"Trait Method Return Type Description <code>PayloadSize</code> <code>size(&amp;self)</code> <code>std::io::Result&lt;u64&gt;</code> Returns the size of the payload body in bytes (excluding the header). <code>PayloadSignature</code> <code>sig(&amp;self)</code> <code>ByteBlock</code> Returns the signature, which can have a variable length of 4, 8, 16, 32, 64, or 128 bytes. <code>StaticPayloadSignature</code> <code>ssig()</code> <code>ByteBlock</code> Similar to <code>sig</code>, but can be called without creating a payload instance. <code>PayloadEncode</code> <code>encode(&amp;self)</code> <code>std::io::Result&lt;Vec&lt;u8&gt;&gt;</code> Creates a binary representation of the payload (excluding the header). <code>PayloadEncodeReferred</code> <code>encode(&amp;self)</code> <code>std::io::Result&lt;Option&lt;&amp;[u8]&gt;&gt;</code> Creates a reference representation of the payload, if possible. Used for calculation of payload CRC and can boost performance <code>PayloadDecode&lt;T&gt;</code> <code>decode(buf: &amp;[u8])</code> <code>std::io::Result&lt;T&gt;</code> Attempts to reconstruct the payload from a byte slice."},{"location":"parts/payloads/#automatically-implemented-traits","title":"Automatically Implemented Traits","text":"<p>The following traits are automatically applied and do not require manual implementation, though they can be overridden if needed:</p> Trait Method Return Type Description <code>PayloadCrc</code> <code>crc(&amp;self)</code> <code>std::io::Result&lt;ByteBlock&gt;</code> Returns the CRC of the payload, which can have a variable length of 4, 8, 16, 32, 64, or 128 bytes. <code>ReadPayloadFrom</code> <code>read&lt;B: std::io::Read&gt;(buf: &amp;mut B, header: &amp;PayloadHeader)</code> <code>Result&lt;T, Error&gt;</code> Reads the payload from a source. <code>TryReadPayloadFrom</code> <code>try_read&lt;B: std::io::Read + std::io::Seek&gt;(buf: &amp;mut B, header: &amp;PayloadHeader)</code> <code>Result&lt;ReadStatus&lt;T&gt;, Error&gt;</code> Attempts to read the payload from a source. If there is insufficient data, it returns a corresponding read status instead of an error. <code>TryReadPayloadFromBuffered</code> <code>try_read&lt;B: std::io::BufRead&gt;(buf: &amp;mut B, header: &amp;PayloadHeader)</code> <code>Result&lt;ReadStatus&lt;T&gt;, Error&gt;</code> Similar to <code>TryReadPayloadFrom</code>, but returns a reference representation of the payload (if supported) instead of the actual payload. <code>WritePayloadWithHeaderTo</code> <code>write&lt;T: std::io::Write&gt;(&amp;mut self, buf: &amp;mut T)</code> <code>std::io::Result&lt;usize&gt;</code> Equivalent to the standard <code>write</code> method, returning the number of bytes written. Does not guarantee that data is flushed to the output, so calling <code>flush</code> is required if such guarantees are needed. <code>WritePayloadWithHeaderTo</code> <code>write_all&lt;T: std::io::Write&gt;(&amp;mut self, buf: &amp;mut T)</code> <code>std::io::Result&lt;()&gt;</code> Equivalent to the standard <code>write_all</code> method. <code>WriteVectoredPayloadWithHeaderTo</code> <code>write_vectored&lt;T: std::io::Write&gt;(&amp;mut self, buf: &amp;mut T)</code> <code>std::io::Result&lt;usize&gt;</code> Attempts a vectored write of the payload (analogous to the standard <code>write_vectored</code>). <code>WriteVectoredPayloadWithHeaderTo</code> <code>slices(&amp;mut self)</code> <code>std::io::Result&lt;IoSlices&gt;</code> Returns the binary representation of the payload as slices. <code>WriteVectoredPayloadWithHeaderTo</code> <code>write_vectored_all&lt;T: std::io::Write&gt;(&amp;mut self, buf: &amp;mut T)</code> <code>std::io::Result&lt;()&gt;</code> Attempts a vectored write of the payload (analogous to the standard <code>write_vectored_all</code>)."},{"location":"parts/payloads/#payload-header-payloadheader","title":"Payload Header (<code>PayloadHeader</code>)","text":"<p>The payload header is not a generated structure but a static one included in the <code>brec</code> crate. <code>PayloadHeader</code> is used when writing a payload into a packet (<code>Packet</code>) and is always written before the payload body itself. When manually writing a payload to a data source, it is strongly recommended to prepend it with <code>PayloadHeader</code> to facilitate further reading from the source.</p> <p><code>PayloadHeader</code> implements the following traits:</p> Trait Method Return Type Description <code>ReadFrom</code> <code>read&lt;T: std::io::Read&gt;(buf: &amp;mut T)</code> <code>Result&lt;Self, Error&gt;</code> Attempts to read <code>PayloadHeader</code> from a source. <code>TryReadFrom</code> <code>try_read&lt;T: std::io::Read + std::io::Seek&gt;(buf: &amp;mut T)</code> <code>Result&lt;ReadStatus&lt;Self&gt;, Error&gt;</code> Attempts to read <code>PayloadHeader</code>, but if data is insufficient, returns a corresponding read status instead of an error. Also, moves the source's position only on successful reading; otherwise, it remains unchanged. <code>TryReadFromBuffered</code> <code>try_read&lt;T: std::io::BufRead&gt;(reader: &amp;mut T)</code> <code>Result&lt;ReadStatus&lt;Self&gt;, Error&gt;</code> Identical to <code>TryReadFrom</code>. <p>Thus, if you are manually implementing payload reading from a source, you should first read <code>PayloadHeader</code>, and then, using the obtained header, proceed to read the payload itself.</p> <p><code>PayloadHeader</code> does not implement any traits for writing to a source. However, it provides the <code>as_vec()</code> method, which returns its binary representation.</p>"},{"location":"parts/payloads/#automatically-supported-payload-types","title":"Automatically Supported Payload Types","text":"<p>Out of the box, <code>brec</code> supports <code>String</code> and <code>Vec&lt;u8&gt;</code> as payload types. After code generation, these will be included in the corresponding enumeration:</p> <pre><code>brec::generate!();\n\npub enum Payload {\n    // ..\n    // User-defined payloads\n    // ..\n    // Default payloads\n    Bytes(Vec&lt;u8&gt;),\n    String(String),\n}\n</code></pre>"},{"location":"parts/payloads/#defining-payloads-with-bincode","title":"Defining Payloads with <code>bincode</code>","text":"<p>Enabling the <code>bincode</code> feature provides the simplest and most flexible way to define payload types. By specifying <code>#[payload(bincode)]</code>, any type that supports <code>serde</code> serialization and deserialization can be used as a <code>payload</code>.</p> <pre><code>#[payload(bincode)]\n#[derive(serde::Deserialize, serde::Serialize)]\npub struct MyPayloadStruct {\n    // User-defined fields\n}\n\n#[payload(bincode)]\n#[derive(serde::Deserialize, serde::Serialize)]\npub enum MyPayloadEnum {\n    // User-defined variants\n}\n</code></pre>"},{"location":"parts/payloads/#partial-restrictions-on-payload-types","title":"Partial Restrictions on Payload Types","text":"<p>It is important to note that the CRC for a payload is generated twice\u2014once when the payload is converted into bytes and again after extraction (to compare with the CRC stored in the payload header). This imposes certain limitations on CRC verification, as <code>brec</code> does not restrict the types of data used in a payload. If a payload contains data types that do not guarantee a strict byte sequence, CRC verification will always fail due to variations in byte order. As a result, extracting such a payload from the stream will become impossible.</p> <p>A simple example of this issue is <code>HashMap</code>, which does not guarantee a consistent field order upon reconstruction. For instance:</p> <pre><code>#[payload(bincode)]\n#[derive(serde::Deserialize, serde::Serialize)]\npub struct MyPayloadB {\n    items: HashMap&lt;String, String&gt;,\n}\n</code></pre> <p>Extracting such a payload will be impossible because the CRC will always be different (except when the number of keys in the map is \u2264 1). This issue can be resolved in several ways:</p> <ul> <li>The simplest approach is to avoid using \"unstable\" data types and instead choose a type that guarantees a fixed byte sequence.</li> <li>Disable CRC verification for this specific payload using the <code>no_crc</code> directive: <code>#[payload(no_crc)]</code>.</li> <li>Disable automatic CRC calculation and implement the <code>PayloadCrc</code> trait manually for the specific payload. This can be done using the <code>no_auto_crc</code> directive: <code>#[payload(bincode, no_auto_crc)]</code>.</li> </ul>"},{"location":"parts/payloads/#payload-parameters","title":"Payload Parameters","text":"<p>The <code>payload</code> macro can be used with the following directives:</p> <ul> <li><code>path = mod::mod</code> \u2013 Specifies the module path for the payload if it is not directly imported at the location of <code>brec::generate!()</code>. This approach is not recommended (it is better to ensure payload visibility at the generator call site), but it is not inherently inefficient or unstable. However, using this method may make future code maintenance more difficult.</li> <li><code>no_crc</code> \u2013 Disables CRC verification for the payload. Note that this does not remove the CRC field from the binary representation of the payload (specifically in <code>PayloadHeader</code>). The CRC field will still be present but filled with zeros, and no CRC calculation will be performed.</li> <li><code>no_auto_crc</code> \u2013 Disables CRC verification for <code>payload(bincode)</code>, requiring a manual implementation of the <code>PayloadCrc</code> trait. This parameter is only relevant when using the <code>bincode</code> feature.</li> <li><code>bincode</code> \u2013 available only when the bincode feature is enabled. It allows using any structure as a payload as long as it meets the requirements of the bincode crate, i.e., it implements serde serialization and deserialization. Please note that bincode has a number of limitations, which you can review in its official documentation.</li> </ul>"},{"location":"stability/performance/","title":"Performance","text":""},{"location":"stability/performance/#performance-and-efficiency","title":"Performance and Efficiency","text":"<p>To evaluate the performance of the protocol, the following data structure is used:</p> <pre><code>pub enum Level {\n    Err,\n    Warn,\n    Info,\n    Debug,\n}\n\npub enum Target {\n    Server,\n    Client,\n    Proxy,\n}\n\n#[block]\npub struct Metadata {\n    pub level: Level,\n    pub target: Target,\n    pub tm: u64,\n}\n</code></pre> <p>Note: Conversion of <code>Level</code> and <code>Target</code> into <code>u8</code> is required but omitted here for brevity.</p> <p>Each packet consists of a <code>Metadata</code> block and a <code>String</code> payload. Data is randomly generated, and a special \"hook\" string is inserted randomly into some messages for use in filtering tests.</p>"},{"location":"stability/performance/#test-description","title":"Test Description","text":"<ul> <li>Storage: Data is written using the <code>brec</code> storage API \u2014 <code>Storage&lt;S: std::io::Read + std::io::Write + std::io::Seek&gt;</code> \u2014 and then read back using the same interface.</li> <li>Binary Stream: Data is written to the file as a plain stream of packets, without slots or metadata. Then it is read using <code>PacketBufReader</code>.</li> <li>Streamed Storage: Data is written using <code>Storage</code>, but read using <code>PacketBufReader</code>, which ignores slot metadata (treating it as garbage).</li> <li>Plain Text: Raw text lines are written to the file, separated by <code>\\n</code>.</li> <li>JSON: The structure shown above is serialized to JSON using <code>serde_json</code> and written as one JSON object per line. During reading, each line is deserialized back to the original structure.</li> </ul> <p>Each test is run in two modes: - Reading \u2014 reading all available data. - Filtering \u2014 reading only records that match specific criteria: logs of type \"error\" and containing a search hook in the payload.</p> <p>Plain Text is used as a baseline due to its minimal overhead \u2014 raw sequential file reading with no parsing or decoding. However, <code>brec</code> performance is more meaningfully compared with JSON, which also involves deserialization. JSON is considered a strong baseline due to its wide use and mature, highly optimized parser.</p>"},{"location":"stability/performance/#important-notes","title":"Important Notes","text":"<ul> <li>For fairness, CRC checks are enabled for all <code>brec</code> component. CRC is calculated for blocks, payloads, and slots (in the case of storage).</li> <li>Each test is repeated multiple times to produce averaged values (<code>Iterations</code> column).</li> </ul>"},{"location":"stability/performance/#test-results","title":"Test Results","text":"Test Mode Size Rows Time (ms) Iterations Storage Filtering 908 Mb 140,000 612 10 Storage Reading 908 Mb 1,000,000 987 10 JSON Reading 919 Mb 1,000,000 597 10 JSON Filtering 919 Mb 140,000 608 10 Binary Stream Reading 831 Mb 1,000,000 764 10 Binary Stream Filtering 831 Mb 140,000 340 10 Plain Text Reading 774 Mb 1,000,000 247 10 Plain Text Filtering 774 Mb 150,000 276 10 Streamed Storage Filtering 908 Mb 140,000 355 10 Streamed Storage Reading 908 Mb 1,000,000 790 10"},{"location":"stability/performance/#observations","title":"Observations","text":"<ul> <li>Plain text is the fastest format by nature and serves as a baseline.</li> <li>Storage gives the slowest reading time in full-scan mode \u2014 which is expected due to CRC verification and slot parsing.</li> <li>However, when filtering is enabled, storage is only 4ms slower than JSON, which is a negligible difference, especially considering that storage data is CRC-protected and recoverable.</li> <li>If the storage file is damaged, packets can still be recovered using <code>PacketBufReader</code>, even if the slot metadata becomes unreadable.</li> <li>Binary stream mode (stream writing and reading with <code>PacketBufReader</code>) shows exceptional filtering performance \u2014 nearly twice as fast as JSON \u2014 and even full reading is only slightly slower than JSON (~167ms on 1 GB), which is not significant in most scenarios.</li> </ul> <p>This efficiency is possible because <code>brec</code>'s architecture allows it to skip unnecessary work. In contrast to JSON, where every line must be deserialized, <code>brec</code> can evaluate blocks before parsing payloads, leading to better filtering performance.</p>"},{"location":"stability/tests/","title":"Tests","text":"<p>The stability of <code>brec</code> is ensured through two levels of testing.</p>"},{"location":"stability/tests/#functional-testing","title":"Functional Testing","text":"<p>To test reading, writing, parsing, filtering, and other functions, <code>brec</code> uses <code>proptest</code> to generate random values for predefined (structurally consistent) blocks and payloads. Blocks and payloads are tested both separately and in combination as part of packet testing. </p> <p>Packets are constructed with randomly generated blocks and payloads. Additionally, the ability of <code>brec</code> tools to reliably read and write randomly generated blocks is also tested, specifically focusing on <code>Storage&lt;S: std::io::Read + std::io::Write + std::io::Seek&gt;</code> and <code>PacketBufReader</code>.</p> <p>In total, over 40 GB of test data is generated for this type of testing.</p>"},{"location":"stability/tests/#macro-testing","title":"Macro Testing","text":"<p>To validate the behavior of the <code>block</code> and <code>payload</code> macros, <code>brec</code> also uses <code>proptest</code>, but this time it not only generates random data but also randomly constructs block and payload structures.</p> <p>Each randomly generated set of structures is saved as a separate crate. After generating these test cases, each one is compiled and executed to ensure stability. Specifically, all randomly generated packets must be successfully encoded and subsequently decoded without errors.</p>"},{"location":"tools/buffer/","title":"Buffer","text":""},{"location":"tools/buffer/#reading-mixed-and-mono-streams","title":"Reading Mixed and Mono Streams","text":"<p>To read from a data source, <code>brec</code> includes the <code>PacketBufReader&lt;R: std::io::Read&gt;</code> tool (available after code generation by calling <code>brec::generate!()</code>). <code>PacketBufReader</code> ensures safe reading from both pure <code>brec</code> message streams and mixed data streams (containing both <code>brec</code> messages and arbitrary data).</p> <p>Below is an example of reading all <code>brec</code> messages from a stream while counting the number of \"junk\" bytes (i.e., data that is not a <code>brec</code> message):</p> <pre><code>fn reading&lt;R: std::io::Read&gt;(source: &amp;mut R) -&gt; std::io::Result&lt;(Vec&lt;Packet&gt;, usize)&gt; {\n    let mut packets: Vec&lt;Packet&gt; = Vec::new();\n    let mut reader: PacketBufReader&lt;_&gt; = PacketBufReader::new(source);\n    let ignored: Arc&lt;AtomicUsize&gt; = Arc::new(AtomicUsize::new(0));\n    let ignored_inner = ignored.clone();\n\n    reader\n        .add_rule(Rule::Ignored(brec::RuleFnDef::Dynamic(Box::new(\n            move |bytes: &amp;[u8]| {\n                ignored_inner.fetch_add(bytes.len(), Ordering::SeqCst);\n            },\n        ))))\n        .unwrap();\n\n    loop {\n        match reader.read() {\n            Ok(next) =&gt; match next {\n                NextPacket::Found(packet) =&gt; packets.push(packet),\n                NextPacket::NotFound =&gt; {\n                    // Data will be refilled on the next call\n                }\n                NextPacket::NotEnoughData(_needed) =&gt; {\n                    // Data will be refilled on the next call\n                }\n                NextPacket::NoData =&gt; {\n                    break;\n                }\n                NextPacket::Skipped =&gt; {\n                    //\n                }\n            },\n            Err(err) =&gt; {\n                return Err(std::io::Error::new(\n                    std::io::ErrorKind::InvalidData,\n                    err.to_string(),\n                ));\n            }\n        };\n    }\n    Ok((packets, ignored.load(Ordering::SeqCst)))\n}\n</code></pre>"},{"location":"tools/buffer/#key-features-of-packetbufreader","title":"Key Features of <code>PacketBufReader</code>","text":"<ul> <li>If there is insufficient data (<code>NextPacket::NotEnoughData</code>), <code>PacketBufReader</code> will attempt to load more data on each subsequent call to <code>read()</code>.  </li> <li>If no <code>brec</code> data is found in the current <code>read()</code> iteration (<code>NextPacket::NotFound</code>), <code>PacketBufReader</code> will also attempt to load more data on each subsequent <code>read()</code>.  </li> </ul> <p>Thus, <code>PacketBufReader</code> automatically manages data loading, removing the need for users to implement their own data-fetching logic.</p>"},{"location":"tools/buffer/#nextpacket-read-statuses","title":"<code>NextPacket</code> Read Statuses","text":"Status Description Can Continue Reading? <code>NextPacket::Found</code> A packet was successfully found and returned. \u2705 Yes <code>NextPacket::NotFound</code> No packets were found in the current read iteration. \u2705 Yes <code>NextPacket::NotEnoughData</code> A packet was detected, but there is not enough data to read it completely. \u2705 Yes <code>NextPacket::Skipped</code> A packet was detected but skipped due to filtering rules. \u2705 Yes <code>NextPacket::NoData</code> No more data can be retrieved from the source. \u274c No <p>After receiving <code>NextPacket::NoData</code>, further calls to <code>read()</code> are meaningless, as <code>PacketBufReader</code> has exhausted all available data from the source.</p>"},{"location":"tools/buffer/#custom-filtering-rules-in-packetbufreader","title":"Custom Filtering Rules in <code>PacketBufReader</code>","text":"<p>Another key feature of <code>PacketBufReader</code> is that users can define custom rules to be applied during data reading. These rules can be updated dynamically between <code>read()</code> calls using <code>add_rule</code> and <code>remove_rule</code>.</p> Rule Available Data Description <code>Rule::Ignored</code> <code>&amp;[u8]</code> Triggered when data not related to <code>brec</code> messages is encountered. Provides a byte slice of the unrelated data. <code>Rule::FilterByBlocks</code> <code>&amp;[BlockReferred&lt;'a&gt;]</code> Triggered when a packet is found and its blocks have been partially parsed. If blocks contain slices, no copying is performed \u2014 <code>BlockReferred</code> will hold references instead. At this stage, the user can decide whether to proceed with parsing the \"heavy\" part (i.e., the payload) or skip the packet. <code>Rule::FilterByPayload</code> <code>&amp;[u8]</code> Allows \"peeking\" into the payload bytes before deserialization. This is especially useful if the payload is, for example, a string \u2014 enabling scenarios like substring search. <code>Rule::Filter</code> <code>&amp;Packet</code> Triggered after the packet is fully parsed, giving the user a final chance to accept or reject the packet. <p>The rules <code>Rule::FilterByBlocks</code> and <code>Rule::FilterByPayload</code> are particularly effective at improving performance, as they allow you to skip the most expensive part \u2014 parsing the payload \u2014 if the packet is not needed.</p>"},{"location":"tools/storage/","title":"Storage","text":""},{"location":"tools/storage/#brec-message-storage","title":"<code>brec</code> Message Storage","text":"<p>In addition to stream reading, <code>brec</code> provides a tool for storing packets and accessing them efficiently \u2014 <code>Storage&lt;S: std::io::Read + std::io::Write + std::io::Seek&gt;</code> (available after invoking <code>brec::generate!()</code>).</p> Method Description <code>insert(&amp;mut self, packet: Packet)</code> Inserts a packet into the storage. <code>add_rule(&amp;mut self, rule: Rule)</code> Adds a filtering rule. <code>remove_rule(&amp;mut self, rule: RuleDefId)</code> Removes a filtering rule. <code>count(&amp;self)</code> Returns the number of records currently stored. <code>iter(&amp;mut self)</code> Returns an iterator over the storage. This method does not apply filters, even if previously added. <code>filtered(&amp;mut self)</code> Returns an iterator with filters applied (if any were set via <code>add_rule</code>). The filtering rules used in <code>Storage</code> are identical to those used in <code>PacketBufReader</code>. <code>nth(&amp;mut self, nth: usize)</code> Attempts to read the packet at the specified index. Note that this method does not apply any filtering, even if filters have been previously defined. <code>range(&amp;mut self, from: usize, len: usize)</code> Returns an iterator over a given range of packets. <code>range_filtered(&amp;mut self, from: usize, len: usize)</code> Returns an iterator over a range of packets with filters applied (if previously set via <code>add_rule</code>). <p>Filtering by blocks or payload improves performance by allowing the system to avoid fully parsing packets unless necessary.</p>"},{"location":"tools/storage/#storage-layout-and-slot-design","title":"Storage Layout and Slot Design","text":"<p>The core design of <code>Storage</code> is based on how it organizes packets internally: - Packets are not stored sequentially but are grouped into slots, with 500 packets per slot. - Each slot stores metadata about packet positions in the file and includes a CRC for slot validation, which makes the storage robust against corruption. - Thanks to the slot metadata, <code>Storage</code> can quickly locate packets by index or return a packet range efficiently.</p> <p>As previously mentioned, each slot maintains its own CRC to ensure data integrity. However, even if the storage file becomes corrupted and <code>Storage</code> can no longer operate reliably, packets remain accessible in a manual recovery mode. For example, you can use <code>PacketBufReader</code> to scan the file, ignoring slot metadata and extracting intact packets sequentially.</p>"},{"location":"tools/storage/#locked-file-storage","title":"Locked file storage","text":"<p>When the locked_storage feature is enabled, you gain access to <code>FileStorage</code>, a file-backed wrapper around <code>StorageDef</code> with built-in file locking capabilities.</p>"},{"location":"tools/storage/#how-it-works","title":"How it works","text":"<p>When a new instance of <code>FileStorage</code> is created, a .lock file is created alongside the target storage file. An exclusive advisory lock is then applied to the .lock file using the fs4 crate.</p> <p>This mechanism ensures that:</p> <ul> <li>Multiple <code>FileStorage</code> instances from the same or different processes will respect the lock</li> <li>Only one instance can access the underlying file at a time</li> <li>Lock contention can be resolved automatically via timeout and polling</li> </ul> <p>Important: This is an advisory lock. It only prevents access for processes that respect the locking protocol (such as other brec-based tools). It does not prevent other unrelated tools, editors, or system calls from modifying the file.</p>"},{"location":"tools/storage/#coordinated-access","title":"Coordinated Access","text":"<p><code>FileStorage</code> supports:</p> <ul> <li>An optional timeout for acquiring the lock</li> <li>A customizable polling interval while waiting</li> </ul> <p>This allows safe coordination in multi-process environments, without resorting to global OS-level locks.</p>"},{"location":"tools/storage/#example","title":"Example","text":"<pre><code>FileStorage::new(\n    &amp;filename,                          // Path to file\n    Some(Duration::from_millis(100)),   // Timeout\n    None,                               // Interval to check lock state (if file was locked and we are waiting)\n);\n\n// Or with options\nFileStorageOptions::new(filename)\n    .timeout(Duration::from_millis(300))\n    .interval(Duration::from_millis(50))\n    .open();\n</code></pre>"}]}